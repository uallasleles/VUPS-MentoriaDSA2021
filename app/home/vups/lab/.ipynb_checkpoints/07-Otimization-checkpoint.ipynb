{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60d28a0-ea69-4dd8-93f8-248d9e217ad0",
   "metadata": {},
   "source": [
    "# OTIMIZAÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186366b5-96d3-4b51-a0e8-cc6a9bb654d0",
   "metadata": {},
   "source": [
    "## Ajuste de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3ab8c-c8b2-4ed8-a3a9-aa24796c15cc",
   "metadata": {},
   "source": [
    "- Grid Search Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2776cbe-71ca-4733-9cc8-841f3c1ca2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Parameter Tuning\n",
      "-> Acurácia: 97.778\n",
      "-> Melhores parâmetros: LogisticRegression(C=10)\n"
     ]
    }
   ],
   "source": [
    "# from pandas import read_csv\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Grid Search Parameter Tuning\n",
    "val_grid = {'penalty': ['l2'],\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Criando o grid\n",
    "grid = GridSearchCV(estimator = modelo,\n",
    "                    param_grid = val_grid)\n",
    "grid.fit(X_escalado, y)\n",
    "\n",
    "# Imprime o resultado\n",
    "print(\"Grid Search Parameter Tuning\")\n",
    "print(\"-> Acurácia: %.3f\" % (grid.best_score_ * 100))\n",
    "print(\"-> Melhores parâmetros:\", grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431620d-254c-4fc8-8be9-918618c1f34a",
   "metadata": {},
   "source": [
    "- Random Search Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0fcc2e67-cbbe-475f-a1c5-ace6cfd87bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search Parameter Tuning\n",
      "-> Acurácia: 97.778\n",
      "-> Melhores parâmetros: LogisticRegression(C=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "iterations = 7\n",
    "\n",
    "val_grid = {'penalty': ['l2'],\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Criando o grid\n",
    "rsearch = RandomizedSearchCV(estimator = modelo,\n",
    "                             param_distributions = val_grid,\n",
    "                             n_iter = iterations,\n",
    "                             random_state = seed)\n",
    "rsearch.fit(X_escalado, y)\n",
    "\n",
    "# Resultados\n",
    "print(\"Random Search Parameter Tuning\")\n",
    "print(\"-> Acurácia: %.3f\" % (rsearch.best_score_ * 100))\n",
    "print(\"-> Melhores parâmetros:\", rsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc62f0-dabe-4f48-9947-0738dcb18850",
   "metadata": {},
   "source": [
    "## Métodos Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbaea26-3659-4f86-8fa7-b74ec76338dc",
   "metadata": {},
   "source": [
    "- Bagged Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9555bed-498f-4512-8cbf-6f4e46504ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Decision Trees\n",
      "-> Acurácia: 95.523\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Cria o modelo unitário (classificador fraco)\n",
    "cart = DecisionTreeClassifier()\n",
    "\n",
    "# Definindo o número de trees\n",
    "n_trees = 100\n",
    "\n",
    "# Criando o modelo bagging\n",
    "modelo = BaggingClassifier(base_estimator = cart,\n",
    "                           n_estimators = n_trees,\n",
    "                           random_state = seed)\n",
    "\n",
    "# Cross Validation\n",
    "rs = cross_val_score(estimator = modelo,\n",
    "                     X = X_escalado,\n",
    "                     y = y,\n",
    "                     cv = kf)\n",
    "print(\"Bagged Decision Trees\")\n",
    "print(\"-> Acurácia: %.3f\" % (rs.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73ed11-57f6-4c3b-8815-271b2ac8f608",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7cb1fe0-7c1d-4826-8207-c0d8d2fd2296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "-> Acurácia: 98.301\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definindo o número de trees\n",
    "n_trees = 100\n",
    "max_features = 3\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = RandomForestClassifier(n_estimators = n_trees,\n",
    "                                max_features = max_features)\n",
    "\n",
    "# Cross Validation\n",
    "rs = cross_val_score(estimator = modelo,\n",
    "                     X = X_escalado,\n",
    "                     y = y,\n",
    "                     cv = kf)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Random Forest\")\n",
    "print(\"-> Acurácia: %.3f\" % (rs.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329d7df-9316-4937-9854-8ad791546c50",
   "metadata": {},
   "source": [
    "- AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39a5fe37-c2ac-48cd-946d-e9e31acc0ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "-> Acurácia: 90.458\n"
     ]
    }
   ],
   "source": [
    "# from pandas import read_csv\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Definindo o número de trees\n",
    "n_trees = 30\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = AdaBoostClassifier(n_estimators = n_trees,\n",
    "                            random_state = seed)\n",
    "\n",
    "# Cross Validation\n",
    "rs = cross_val_score(estimator = modelo,\n",
    "                     X = X_escalado,\n",
    "                     y = y,\n",
    "                     cv = kf)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"AdaBoost\")\n",
    "print(\"-> Acurácia: %.3f\" % (rs.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9374969-6d36-49d0-942d-b20c0fddac37",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "36e76261-811c-48a7-a0a7-1e8f86ccc151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "-> Acurácia: 92.647\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "# from pandas import read_csv\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Definindo o número de trees\n",
    "n_trees = 100\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = GradientBoostingClassifier(n_estimators = n_trees,\n",
    "                                    random_state = seed)\n",
    "\n",
    "# Cross Validation\n",
    "rs = cross_val_score(estimator = modelo,\n",
    "                     X = X_escalado,\n",
    "                     y = y,\n",
    "                     cv = kf)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Gradient Boosting\")\n",
    "print(\"-> Acurácia: %.3f\" % (rs.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd5aac-579a-4aff-b25c-aa6cecf265b5",
   "metadata": {},
   "source": [
    "- Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "375f8e31-ebd1-44f3-acaa-cdcd360a6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble\n",
      "-> Acurácia: 98.856\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "#from pandas import read_csv\n",
    "#from sklearn.model_selection import KFold\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Criando os modelos\n",
    "estimators = []\n",
    "\n",
    "modelo1 = LogisticRegression()\n",
    "estimators.append(('logistic', modelo1))\n",
    "\n",
    "modelo2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', modelo2))\n",
    "\n",
    "modelo3 = SVC()\n",
    "estimators.append(('svm', modelo3))\n",
    "\n",
    "# Criando o modelo ensemble\n",
    "ensemble = VotingClassifier(estimators)\n",
    "\n",
    "# Cross Validation\n",
    "rs = cross_val_score(estimator = ensemble,\n",
    "                     X = X_escalado,\n",
    "                     y = y,\n",
    "                     cv = kf)\n",
    "\n",
    "# Resultado\n",
    "print(\"Voting Ensemble\")\n",
    "print(\"-> Acurácia: %.3f\" % (rs.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39151d82-bc6b-4340-a712-a60950ca10a1",
   "metadata": {},
   "source": [
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "747ab19e-b2c8-4e5b-a793-a9029859fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Gradient Boosting\n",
    "# !pip install xgboost\n",
    "# !conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b24d607d-e276-43e3-a208-64bb5dec4be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 98.31%\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "#from pandas import read_csv\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "# Definindo o tamanho dos dados de treino e de teste\n",
    "teste_size = 0.33\n",
    "\n",
    "# Criando o dataset de treino e de teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(X_escalado, y,\n",
    "                                                        test_size = teste_size,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = XGBClassifier(use_label_encoder=False, \n",
    "                       eval_metric='mlogloss')\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(x_treino, y_treino)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred = modelo.predict(x_teste)\n",
    "previsoes = [round(value) for value in y_pred]\n",
    "\n",
    "# Avaliando as previsões\n",
    "accuracy = accuracy_score(y_teste, previsoes)\n",
    "print(\"Acurácia: %.2f%%\" % (accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
